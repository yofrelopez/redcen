
name: Daily News Scraper

on:
  schedule:
    # Ejecutar 3 veces al día: 6am, 12pm, 6pm (Hora Perú UTC-5)
    # - 11:00 UTC = 06:00 PE
    # - 17:00 UTC = 12:00 PE
    # - 23:00 UTC = 18:00 PE
    # - cron: '0 11,17,23 * * *'
  # Permite ejecutar manualmente desde la pestaña Actions
  workflow_dispatch:
    inputs:
      hour:
        description: 'Hora específica (ej: 6, 12, 18). Vacío = Hora Actual.'
        required: false
        type: string

jobs:
  scrape-and-ingest:
    runs-on: ubuntu-latest
    
    env:
      # Secretos disponibles para todos los pasos (incluyendo npm install)
      APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
      INGEST_API_SECRET: ${{ secrets.INGEST_API_SECRET }}
      INGEST_URL: ${{ secrets.INGEST_URL }}
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
      CLOUDINARY_API_KEY: ${{ secrets.CLOUDINARY_API_KEY }}
      CLOUDINARY_API_SECRET: ${{ secrets.CLOUDINARY_API_SECRET }}
      NEXT_PUBLIC_CLOUDINARY_CLOUD_NAME: ${{ secrets.NEXT_PUBLIC_CLOUDINARY_CLOUD_NAME }}

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      - name: Generate Prisma Client
        run: npx prisma generate

      - name: Run Scraper Service
        run: npx tsx jobs/scraper-service.ts --hour="${{ github.event.inputs.hour }}"
