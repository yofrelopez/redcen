
name: Daily News Scraper

on:
  schedule:
    # Ejecutar todos los días a las 6:00 AM hora Perú (UTC-5)
    # 6:00 AM Perú = 11:00 AM UTC
    - cron: '0 11 * * *'
  # Permite ejecutar manualmente desde la pestaña Actions
  workflow_dispatch:

jobs:
  scrape-and-ingest:
    runs-on: ubuntu-latest
    
    env:
      # Secretos disponibles para todos los pasos (incluyendo npm install)
      APIFY_TOKEN: ${{ secrets.APIFY_TOKEN }}
      INGEST_API_SECRET: ${{ secrets.INGEST_API_SECRET }}
      INGEST_URL: ${{ secrets.INGEST_URL }}
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
      CLOUDINARY_API_KEY: ${{ secrets.CLOUDINARY_API_KEY }}
      CLOUDINARY_API_SECRET: ${{ secrets.CLOUDINARY_API_SECRET }}
      NEXT_PUBLIC_CLOUDINARY_CLOUD_NAME: ${{ secrets.NEXT_PUBLIC_CLOUDINARY_CLOUD_NAME }}

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'npm'

      - name: Install Dependencies
        run: npm ci

      - name: Generate Prisma Client
        run: npx prisma generate

      - name: Run Scraper Service
        run: npx tsx jobs/scraper-service.ts
